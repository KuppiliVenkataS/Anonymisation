{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. This is the anonymization script in python.\n",
    "2. It is tested on Mac only. Not tested on Windows and linux machines.\n",
    "3. Needs python 3 to run.\n",
    "4. Users need to download facebook information in the json format.\n",
    "5. There are only three buttons. \n",
    "    (i) to specify the path of the directory where facebook info is saved, \n",
    "    (ii) generates the output files  in a directory called 'outputDir' within the facebook info directory.\n",
    "    (iii) to quit the application\n",
    "6. outputDir contains all relevant files in .csv format. \n",
    "7. Files with names starting 'temp_' are temporary files generated. Please ignore them.\n",
    "8. The original convertion between username to unique codes file is named as  'master_file_for_info_all_friends.csv'\n",
    "9. Unknown user is represented with id u_999999999.\n",
    "10. my_id  (self id) is always u_100000001.\n",
    "11. Groups are identified by id numbers (example, 'g_10'). They are stored in groups.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from pprint import pprint\n",
    "from pandas.io.json import json_normalize #package for flattening json to pandas df\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import re\n",
    "\n",
    "from unidecode import unidecode\n",
    "import string\n",
    "printable = set(string.printable)\n",
    "\n",
    "my_id = 'u_1000000001'\n",
    "my_name = '' \n",
    "unknown_friend_id = 'u_999999999'\n",
    "unknown_friend_name = 'unknown' # not really necessary\n",
    "encoding_code ='utf-8'\n",
    "char_avoid = ['!','@','£','$','%','^','&','*','(',')','€','#','§','±','=','+']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utility functions\n",
    "def print_full(x):\n",
    "    # This is a support function. To test and check the output.\n",
    "    pd.set_option('display.max_rows', len(x))\n",
    "    #print(x)\n",
    "    #pd.set_option('display.max_colwidth', -1)\n",
    "    pd.reset_option('display.max_rows')\n",
    "    \n",
    "def unidecode_user_names(name):\n",
    "    # This function is a support function - accepts a string and unidecodes it    \n",
    "    name1 =  ''.join(filter(lambda ch: ch not in char_avoid, name))\n",
    "    name1 =  unidecode(name1)\n",
    "    return name1\n",
    "\n",
    "def get_the_user_name(words, j, stop_word):\n",
    "    # This is a support function to extract user's name from message\n",
    "    # here stop_word is the word that follows immediately the user's name   \n",
    "    some_body = ''            \n",
    "    while ( words[j] != stop_word):\n",
    "        some_body = some_body +words[j]+' '\n",
    "        j += 1\n",
    "    some_body = some_body[:-3]\n",
    "    some_body = unidecode_user_names(some_body)   \n",
    "    return some_body\n",
    "\n",
    "def get_file(folder, file_to_search):\n",
    "    if (file_to_search == 'posts'):\n",
    "        choice = r'your_posts*[.json]'\n",
    "    elif (file_to_search == 'messages'):\n",
    "        choice = r'message*[.json]'\n",
    "        \n",
    "    files = []\n",
    "    for (_,_, filenames) in os.walk(folder):\n",
    "        \n",
    "        files.extend(filenames)\n",
    "        break\n",
    "    \n",
    "    for file in files:\n",
    "        if( re.match(choice, file)):\n",
    "            #print(file)\n",
    "            posts_file = file\n",
    "            break\n",
    "    return '/'+file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create friend.csv -- task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These functions are used to create friend.csv file\n",
    "\n",
    "def join_friends_names(names):\n",
    "    # This function joins user names (after converting them to lowercase and remove spaces)\n",
    "    #supports messages folder as messages from individual friends are arranged with names.\n",
    "    \n",
    "    joined_names = pd.Series()\n",
    "    for i in range(0,len(names)):\n",
    "        name = names[i].lower()\n",
    "        name = name.replace(\" \",\"\")\n",
    "        joined_names.at[i] = name\n",
    "    return joined_names\n",
    "\n",
    "def set_my_name(directoryPath):\n",
    "    try:\n",
    "        profile_file = directoryPath+'/profile_information/profile_information.json'\n",
    "        with open(profile_file) as f:\n",
    "            prof_data = json.load(f)\n",
    "\n",
    "        prof_df = json_normalize(prof_data['profile'])\n",
    "        my_name = str(prof_df['name.full_name'][0] )+''\n",
    "    except:\n",
    "        my_name = ''\n",
    "    return my_name\n",
    "    \n",
    "    \n",
    "def read_friends_data_folder(directoryPath):\n",
    "    # This function gathers all friends data from friends folder and generates a dataframe\n",
    "    \n",
    "    friends_folder = directoryPath+'/friends'\n",
    "    friends_df = None\n",
    "    new_df = None\n",
    "    if (os.path.isdir(friends_folder)):\n",
    "        \n",
    "        if (os.path.isfile(friends_folder +'/friends.json')):\n",
    "            with open(friends_folder +'/friends.json') as f:\n",
    "                friends_data = json.load(f)\n",
    "            friends_df = json_normalize(friends_data['friends'])\n",
    "            if ('contact_info' in friends_df.columns):\n",
    "                friends_df = friends_df.drop('contact_info',1)\n",
    "            friends_df['status'] = 'current friend'\n",
    "            friends_df['type_of_activity'] = 1\n",
    "    \n",
    "        #received_requests\n",
    "        if (os.path.isfile(friends_folder +'/received_friend_requests.json')):\n",
    "            with open(friends_folder+'/received_friend_requests.json') as f:\n",
    "                received_requests_data = json.load(f)\n",
    "\n",
    "            received_requests_df = json_normalize(received_requests_data['received_requests'])\n",
    "            received_requests_df['status'] = 'received request'\n",
    "            received_requests_df['type_of_activity'] = 3\n",
    "\n",
    "            #new_df  = friends_df.append(received_requests_df,ignore_index=True)\n",
    "            friends_df  = friends_df.append(received_requests_df,ignore_index=True)\n",
    "\n",
    "        # rejected requests\n",
    "        if (os.path.isfile(friends_folder +'/rejected_friend_requests.json')):\n",
    "            with open(friends_folder+'/rejected_friend_requests.json') as f:\n",
    "                rejected_requests_data = json.load(f)\n",
    "\n",
    "            rejected_requests_df = json_normalize(rejected_requests_data['rejected_requests'])\n",
    "            if ('marked_as_spam' in rejected_requests_df.columns):\n",
    "                rejected_requests_df = rejected_requests_df.drop('marked_as_spam',1)\n",
    "            rejected_requests_df['status'] = 'rejected request'\n",
    "            rejected_requests_df['type_of_activity'] = 4\n",
    "\n",
    "            #new_df = new_df.append(rejected_requests_df,ignore_index=True)\n",
    "            friends_df  = friends_df.append(rejected_requests_df,ignore_index=True)\n",
    "            \n",
    "        # removed friends\n",
    "        if (os.path.isfile(friends_folder +'/removed_friends.json')):\n",
    "            with open(friends_folder+'/removed_friends.json') as f:\n",
    "                removed_friends_data = json.load(f)\n",
    "\n",
    "            removed_friends_df = json_normalize(removed_friends_data['deleted_friends'])\n",
    "            removed_friends_df['status'] = 'deleted friend'\n",
    "            removed_friends_df['type_of_activity'] = 0\n",
    "\n",
    "            #new_df = new_df.append(removed_friends_df,ignore_index=True)\n",
    "            friends_df  = friends_df.append(removed_friends_df,ignore_index=True)\n",
    "\n",
    "        #sent requests\n",
    "        if (os.path.isfile(friends_folder +'/sent_friend_requests.json')):\n",
    "            with open(friends_folder+'/sent_friend_requests.json') as f:\n",
    "                sent_friend_requests_data = json.load(f)\n",
    "\n",
    "            sent_friend_requests_df = json_normalize(sent_friend_requests_data['sent_requests'])\n",
    "            sent_friend_requests_df['status'] ='sent request'\n",
    "            sent_friend_requests_df['type_of_activity'] = 2\n",
    "\n",
    "            #new_df = new_df.append(sent_friend_requests_df,ignore_index=True)\n",
    "            friends_df  = friends_df.append(sent_friend_requests_df,ignore_index=True)\n",
    "\n",
    "        #new_df['name'] = new_df['name'].apply(lambda x: ''.join(filter(lambda z: z not in char_avoid, x)))\n",
    "        friends_df['name']  = friends_df['name'].apply(lambda x: ''.join(filter(lambda z: z not in char_avoid, x)))\n",
    "        \n",
    "        #new_df['name'] = new_df['name'].apply(lambda x: unidecode(x))\n",
    "        friends_df['name']  = friends_df['name'].apply(lambda x: unidecode(x))\n",
    "        \n",
    "        #new_df['joined_names'] =  join_friends_names(new_df['name'])\n",
    "        friends_df['joined_names']  = join_friends_names(friends_df['name'])\n",
    "    \n",
    "    #return new_df\n",
    "    if (friends_df is None):\n",
    "        friends_df = pd.DataFrame(columns=['name','timestamp','status','type_of_activity','joined_names'])\n",
    "    return friends_df\n",
    "\n",
    "def make_unique_identifier(df):\n",
    "    \n",
    "    # This function calculates a unique id from the details and assigns this id to each friend\n",
    "    combined_id = pd.Series()\n",
    "    \n",
    "    for i in range(0,len(df)):\n",
    "        \n",
    "        # to create a numeric value from name \n",
    "        input = df['name'][i].lower()\n",
    "        output = 0\n",
    "        for character in input:\n",
    "            number = ord(character) - 96 \n",
    "            output = output+number\n",
    "        \n",
    "        # to create a numeric value from name \n",
    "        input = df['status'][i].lower()\n",
    "        for character in input:\n",
    "            number = ord(character) - 96\n",
    "            output = output+number\n",
    "        \n",
    "        output = 'u_'+str(output+df['timestamp'][i])\n",
    "        \n",
    "        combined_id.at[i] = output\n",
    "    return combined_id\n",
    "\n",
    "def generate_friend_csv(directoryPath, outputPath):\n",
    "       \n",
    "    #this function generates two files :\n",
    "    #(i) All data (to be saved on the user's own machine - outputDir/master_file_for_info_all_friends.csv), \n",
    "    #(ii) data with name anonymized --friend.csv\n",
    "    \n",
    "    friends_folder = directoryPath+'/friends'\n",
    "    dataFiles_df = read_friends_data_folder(directoryPath)\n",
    "    #print(dataFiles_df.head(2))\n",
    "    dataFiles_df['from_id'] = my_id \n",
    "    dataFiles_df['to_id'] = make_unique_identifier(dataFiles_df[['name','timestamp','status']])\n",
    "    dataFiles_df['timestamp_date'] = dataFiles_df['timestamp'].apply(lambda x: datetime.datetime.fromtimestamp(x).isoformat() )\n",
    "    dataFiles_df['unique_id'] = dataFiles_df['to_id'] \n",
    "    # Even though 'unique_id' is same as 'to_id', I have made a separate column for backup and clarity\n",
    "    \n",
    "    if not os.path.exists(outputPath):\n",
    "        os.makedirs(outputPath)\n",
    "\n",
    "    dataFiles_df.to_csv(outputPath+'/master_file_for_info_all_friends.csv', sep=',')# no need for 'encoding' parameter as we have already done that\n",
    "\n",
    "    friends_uniqueid = pd.DataFrame(dataFiles_df[['from_id','to_id', 'type_of_activity']].copy())\n",
    "    friends_uniqueid.to_csv(outputPath+'/friend.csv', sep=',') \n",
    "\n",
    "\n",
    "#test this unit\n",
    "#directoryPath = '/media/santhilata/SANTHI/facebook-paulyoung583234/'\n",
    "directoryPath = '/media/santhilata/SANTHI/facebook-maitevanalboom-3/'\n",
    "#outputPath = '/home/santhilata/Desktop/testFolder/paul'\n",
    "outputPath = '/home/santhilata/Desktop/testFolder/maite'\n",
    "\n",
    "read_friends_data_folder(directoryPath)\n",
    "generate_friend_csv(directoryPath, outputPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Group info ** (creation of groups.csv in the format groups(user_id, list_friends, group_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"    \\n#test this unit\\n#directoryPath = '/media/santhilata/SANTHI/facebook-paulyoung583234/'\\ndirectoryPath = '/media/santhilata/SANTHI/facebook-maitevanalboom-3/'\\n#outputPath = '/home/santhilata/Desktop/testFolder/paul'\\noutputPath = '/home/santhilata/Desktop/testFolder/maite'\\ncreate_group_information(directoryPath, outputPath)\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_group_information(directoryPath, outputPath):\n",
    "    # this function creates group.csv \n",
    "    \n",
    "    friends_df = pd.read_csv(outputPath+'/master_file_for_info_all_friends.csv')\n",
    "    groups_folder = directoryPath+'/groups'\n",
    "    \n",
    "    my_groups = pd.DataFrame(columns=['user_id','group_id','admin/member','group_name','joined_date'])\n",
    "    if (os.path.isdir(groups_folder)):\n",
    "        # group memberships \n",
    "        \n",
    "        user_id = my_id\n",
    "        group_id =0\n",
    "        \n",
    "        if (os.path.isfile(groups_folder+'/your_group_membership_activity.json') ):\n",
    "            with open(groups_folder+'/your_group_membership_activity.json' ) as f:\n",
    "                my_group_memberships = json.load(f)\n",
    "\n",
    "\n",
    "            my_group_memberships_df = json_normalize(my_group_memberships['groups_joined'], record_path=['attachments','data'],\n",
    "                                                     meta = ['timestamp','title'])\n",
    "            for i in range(0, len(my_group_memberships_df)) :\n",
    "                admin_member = 'member'\n",
    "\n",
    "                group_name = my_group_memberships_df.loc[i]['name']\n",
    "                joined_date = datetime.datetime.fromtimestamp(my_group_memberships_df.loc[i]['timestamp']).isoformat()\n",
    "\n",
    "                my_groups.loc[group_id] = [user_id,('g_'+str(group_id)),admin_member,group_name,joined_date]\n",
    "                group_id += 1\n",
    "\n",
    "        # add groups_admined\n",
    "        if (os.path.isfile(groups_folder+'/your_groups.json') ):\n",
    "            with open(groups_folder+'/your_groups.json') as f:\n",
    "                your_groups = json.load(f)\n",
    "\n",
    "            your_groups_df = json_normalize(your_groups['groups_admined'])  \n",
    "\n",
    "            for i in range(0, len(your_groups_df)):\n",
    "                admin_member = 'admin'\n",
    "                group_name = your_groups_df.loc[i]['name']\n",
    "\n",
    "                joined_date = datetime.datetime.fromtimestamp(your_groups_df.loc[i]['timestamp']).isoformat()\n",
    "\n",
    "                my_groups.loc[group_id] = [user_id,('g_'+str(group_id)),admin_member,group_name,joined_date]\n",
    "                group_id += 1\n",
    "    \n",
    "    #print(my_groups.tail(10))\n",
    "    my_groups.to_csv(outputPath+'/groups.csv', sep=',')\n",
    "'''    \n",
    "#test this unit\n",
    "#directoryPath = '/media/santhilata/SANTHI/facebook-paulyoung583234/'\n",
    "directoryPath = '/media/santhilata/SANTHI/facebook-maitevanalboom-3/'\n",
    "#outputPath = '/home/santhilata/Desktop/testFolder/paul'\n",
    "outputPath = '/home/santhilata/Desktop/testFolder/maite'\n",
    "create_group_information(directoryPath, outputPath)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#test this unit\\n#directoryPath = '/media/santhilata/SANTHI/facebook-paulyoung583234/'\\ndirectoryPath = '/media/santhilata/SANTHI/facebook-maitevanalboom-3/'\\n#outputPath = '/home/santhilata/Desktop/testFolder/paul'\\noutputPath = '/home/santhilata/Desktop/testFolder/maite'\\ngroup_posts_comments(directoryPath,outputPath)\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def group_posts_comments(directoryPath, outputPath):\n",
    "    \n",
    "    # This function is to create a group_comments.csv file\n",
    "    # The 'your_posts_and_comments_in_groups.json' file has sparse values, which makes things very difficult normalize\n",
    "    # First, I am adding all single comments \n",
    "    # and then, adding comments from attachments\n",
    "    \n",
    "    my_name= set_my_name(directoryPath)\n",
    "    friends_df = pd.read_csv(outputPath+'/master_file_for_info_all_friends.csv')\n",
    "    groups_folder = directoryPath+'/groups'\n",
    "    \n",
    "    \n",
    "    groups_df = pd.read_csv(outputPath+'/groups.csv')\n",
    "    groups_posts = None # to check whether it is existing\n",
    "    \n",
    "    '''\n",
    "    json_normalize() is not handling NAN values in the nested columns properly and causing 'key error'.\n",
    "    So, I tried this work-around below.\n",
    "    step 1: I read the json file using json.load(file_handle)\n",
    "    step 2: convert to pandas data frame\n",
    "    step 3: remove NAN values\n",
    "    step 4: Keep only the columns you need\n",
    "    step 5: convert the dataframe back to json\n",
    "    step 6: json_normalise() the new json file\n",
    "    '''\n",
    "    if (os.path.isfile(groups_folder+'/your_posts_and_comments_in_groups.json') ):    \n",
    "        with open(groups_folder+'/your_posts_and_comments_in_groups.json') as f:\n",
    "            group_comments_posts = json.load(f) # step 1\n",
    "        #pprint(group_comments_posts)\n",
    "\n",
    "\n",
    "        groups_comments_posts_df = json_normalize(data = group_comments_posts['group_posts']) # step 2\n",
    "        if ('activity_log_data' in groups_comments_posts_df.columns):\n",
    "            groups_comments_posts_df = json_normalize(data = group_comments_posts['group_posts']['activity_log_data'])\n",
    "            \n",
    "        groups_comments_posts_df = groups_comments_posts_df.dropna(subset=['data','timestamp','title'],how='any') #step 3\n",
    "        groups_comments_posts_df = groups_comments_posts_df[['data','timestamp','title']].copy() # step 4\n",
    "        #print(groups_comments_posts_df.head(10))\n",
    "        \n",
    "        groups_comments_posts_json = groups_comments_posts_df.to_json(outputPath+'/temp_your_group_posts.json',\n",
    "                                                                      orient='records') #step 5\n",
    "    \n",
    "        if (os.path.isfile(outputPath+'/temp_your_group_posts.json') ):    \n",
    "            with open(outputPath+'/temp_your_group_posts.json') as f:\n",
    "                group_comments_posts = json.load(f)\n",
    "\n",
    "            groups_comments_posts_df = json_normalize(group_comments_posts,'data',['timestamp','comment'], \n",
    "                                                      record_prefix = '*',errors='ignore', meta_prefix='_' )#step 6\n",
    "\n",
    "            #print(groups_comments_posts_df.columns)\n",
    "            #print(groups_comments_posts_df['*comment'][0]) #we need info from this only\n",
    "            groups_posts = pd.DataFrame(columns=['user_id','comment','length_of_comment','timestamp',\n",
    "                                                 'timestamp_date','group_id','group_name'])\n",
    "    \n",
    "        for i in range(0, len(groups_comments_posts_df)):\n",
    "            try:\n",
    "                comment = groups_comments_posts_df['*comment'][i]    \n",
    "                author = unidecode_user_names(comment['author'])\n",
    "                #print(author)\n",
    "                try:\n",
    "                    user_id = my_id if (author == my_name) else (friends_df.loc[comment['author']==friends_df['name'],\n",
    "                                                                                'unique_id'].values[0])\n",
    "                except:\n",
    "                    user_id = unknown_friend_id # an unknown user from a public group\n",
    "                #print(user_id)\n",
    "                comment_post = comment['comment']\n",
    "                length = len(comment_post)\n",
    "                timestamp = comment['timestamp']\n",
    "                timestamp_date = datetime.datetime.fromtimestamp(timestamp).isoformat()\n",
    "                group_name = comment['group']\n",
    "                group_id = groups_df[groups_df['group_name'] == group_name]['group_id'].values[0]\n",
    "\n",
    "                groups_posts.loc[i] = [user_id,comment_post, length, timestamp, timestamp_date,group_id,group_name]\n",
    "                #print(groups_posts.loc[i])\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    #Now add attachments comments\n",
    "    if (os.path.isfile(groups_folder+'/your_posts_and_comments_in_groups.json') ):\n",
    "        with open(groups_folder+'/your_posts_and_comments_in_groups.json') as f:\n",
    "            group_comments_posts1 = json.load(f) \n",
    "        #pprint(group_comments_posts)\n",
    "        groups_comments_posts1_df = json_normalize(data = group_comments_posts1['group_posts']) \n",
    "        if ('activity_log_data' in groups_comments_posts1_df.columns):\n",
    "            groups_comments_posts1_df = json_normalize(data = group_comments_posts1['group_posts']['activity_log_data'])\n",
    "        #print()   \n",
    "        groups_comments_posts1_df = groups_comments_posts1_df.dropna(subset=['attachments']).reset_index(drop=True) \n",
    "        groups_comments_posts1_df = groups_comments_posts1_df[['attachments']].copy() \n",
    "\n",
    "        groups_comments_posts_json = groups_comments_posts1_df.to_json(outputPath+'/temp_your_group_posts1.json',\n",
    "                                                                       orient='records') #step 5\n",
    "\n",
    "        with open(outputPath+'/temp_your_group_posts1.json') as f:\n",
    "            group_comments_posts1 = json.load(f)\n",
    "\n",
    "        groups_comments_posts1_df = json_normalize(group_comments_posts1,['attachments','data'])\n",
    "        groups_comments_posts_media_df = groups_comments_posts1_df['media'].to_frame().dropna().reset_index(drop=True)\n",
    "\n",
    "        counter = len(groups_posts)\n",
    "        for i in range(0,len(groups_comments_posts_media_df)):\n",
    "            try:\n",
    "                row = groups_comments_posts_media_df['media'][i]['comments']\n",
    "\n",
    "                for item in row:\n",
    "                    for key in item:\n",
    "                        if (key == 'comment'):\n",
    "                            comment_post = item[key]\n",
    "                            length = len(comment_post)\n",
    "                        elif (key == 'timestamp'):\n",
    "                            timestamp = item['timestamp']\n",
    "                            timestamp_date = datetime.datetime.fromtimestamp(timestamp).isoformat()\n",
    "                        elif (key == 'author'):\n",
    "                            author = item['author']\n",
    "                            author = unidecode_user_names(author)\n",
    "                            try:\n",
    "                                user_id = my_id if (author == my_name) else (friends_df.loc[author==friends_df['name'],\n",
    "                                                                                            'unique_id'].values[0])\n",
    "                            except:\n",
    "                                user_id = unknown_friend_id # an unknown user from a public group\n",
    "                        elif (key == 'group'):\n",
    "                            group_name = item['group']\n",
    "                            group_id = groups_df[groups_df['group_name'] == group_name]['group_id'].values[0]\n",
    "\n",
    "                    groups_posts.loc[counter] = [user_id,comment_post, length, timestamp, timestamp_date,\n",
    "                                                 group_id,group_name]\n",
    "                    counter += 1\n",
    "\n",
    "\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    \n",
    "    if (groups_posts is not None):\n",
    "        groups_posts.to_csv(outputPath+'/groups_comments.csv',sep=',')\n",
    "    else:\n",
    "        groups_posts = pd.DataFrame(columns=['user_id','comment','length_of_comment','timestamp',\n",
    "                                                 'timestamp_date','group_id','group_name'])\n",
    "        groups_posts.to_csv(outputPath+'/groups_comments.csv',sep=',')\n",
    "'''\n",
    "#test this unit\n",
    "#directoryPath = '/media/santhilata/SANTHI/facebook-paulyoung583234/'\n",
    "directoryPath = '/media/santhilata/SANTHI/facebook-maitevanalboom-3/'\n",
    "#outputPath = '/home/santhilata/Desktop/testFolder/paul'\n",
    "outputPath = '/home/santhilata/Desktop/testFolder/maite'\n",
    "group_posts_comments(directoryPath,outputPath)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create message.csv - task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"    \\n#test this unit\\n#directoryPath = '/media/santhilata/SANTHI/facebook-paulyoung583234/'\\ndirectoryPath = '/media/santhilata/SANTHI/facebook-maitevanalboom-3/'\\n#outputPath = '/home/santhilata/Desktop/testFolder/paul'\\noutputPath = '/home/santhilata/Desktop/testFolder/maite'\\nread_messages_inbox(directoryPath, outputPath)\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_messages_inbox(directoryPath, outputPath):\n",
    "   \n",
    "    #this function is to read all messages, anonymize and generate the output file with length of the messages\n",
    "    friends_df = pd.read_csv(outputPath+'/master_file_for_info_all_friends.csv')\n",
    "    messages_folder = directoryPath+'/messages/inbox'\n",
    "    \n",
    "    final_msg_df = pd.DataFrame([])\n",
    "    \n",
    "    for folder in os.listdir(messages_folder):\n",
    "        folder_friendName = folder.split(\"_\")[0].lower()\n",
    "        \n",
    "        # check whether the folder is a conversation with a friend. We ignore system files ex: ds.store\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            if (len(folder.split(\"_\")[1])>0 ): \n",
    "                \n",
    "                # extract unique id. Incase, the friend's name is not in the friend list, ignore.        \n",
    "                try:\n",
    "                    #print(messages_folder+'/'+folder)\n",
    "                    uniqueid = friends_df.loc[friends_df['joined_names']==folder_friendName,'unique_id'].values[0]\n",
    "                    #print(uniqueid)\n",
    "                    friend_name = friends_df.loc[friends_df['joined_names']==folder_friendName,'name'].values[0]\n",
    "\n",
    "                    # read data from messages \n",
    "                    \n",
    "                    #print(get_file(messages_folder+'/'+folder,'messages'))\n",
    "                    \n",
    "                    message_file = messages_folder+'/'+ folder + get_file(messages_folder+'/'+folder,'messages')\n",
    "                    #print(message_file)\n",
    "\n",
    "                    try:\n",
    "                        with open(message_file) as f:\n",
    "                            messages = json.load(f)\n",
    "\n",
    "                        messages_df = json_normalize(messages['messages'])\n",
    "                        #print(messages_df.head(1))\n",
    "\n",
    "                        messages_df['from_id'] = np.where(messages_df['sender_name']==friend_name,uniqueid,my_id)\n",
    "                        messages_df['to_id'] = np.where(messages_df['sender_name'] ==friend_name,my_id, uniqueid)\n",
    "                        messages_df['length_of_msg']  = messages_df['content'].apply(lambda x: len(x))\n",
    "                        messages_df = messages_df[[ 'from_id', 'to_id', 'length_of_msg', 'timestamp_ms']].copy()\n",
    "\n",
    "                        final_msg_df = final_msg_df.append(messages_df)\n",
    "                    except:\n",
    "                        continue\n",
    "\n",
    "                except: \n",
    "                    continue\n",
    "\n",
    "            else: \n",
    "                continue\n",
    "        except:\n",
    "            continue\n",
    "    final_msg_df = final_msg_df.reset_index()\n",
    "    final_msg_df['timestamp_date'] = final_msg_df['timestamp_ms'].apply(lambda x: datetime.datetime.fromtimestamp(int(x/1000)).isoformat())\n",
    "    \n",
    "    #print(final_msg_df.head(10))    \n",
    "    final_msg_df.to_csv(outputPath+'/message.csv', sep=',')\n",
    "\n",
    "'''    \n",
    "#test this unit\n",
    "#directoryPath = '/media/santhilata/SANTHI/facebook-paulyoung583234/'\n",
    "directoryPath = '/media/santhilata/SANTHI/facebook-maitevanalboom-3/'\n",
    "#outputPath = '/home/santhilata/Desktop/testFolder/paul'\n",
    "outputPath = '/home/santhilata/Desktop/testFolder/maite'\n",
    "read_messages_inbox(directoryPath, outputPath)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timeline posts - task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#test this unit\\n#directoryPath = '/media/santhilata/SANTHI/facebook-paulyoung583234/'\\ndirectoryPath = '/media/santhilata/SANTHI/facebook-maitevanalboom-3/'\\n#outputPath = '/home/santhilata/Desktop/testFolder/paul'\\noutputPath = '/home/santhilata/Desktop/testFolder/maite'\\npost = pd.DataFrame(columns = ['user_id_from','user_id_to','post_id','timestamp','timestamp_date','post_activity'])\\nread_comments(directoryPath, outputPath, post)\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To create post.csv, data is retrieved from the following:\n",
    "#(i) comments/comments.json\n",
    "#(ii)likes_and_reactions/posts_and_comments.json\n",
    "#(iii) posts/your_posts.json\n",
    "# It is possible that some of the comments are duplicated.\n",
    "# So, I tried to sort them with timestamp column.\n",
    "\n",
    "def read_comments(directoryPath, outputPath, post):\n",
    "    friends_df = pd.read_csv(outputPath+'/master_file_for_info_all_friends.csv')\n",
    "    groups_df = pd.read_csv(outputPath+'/groups.csv')\n",
    "    comments_folder = directoryPath+'/comments'\n",
    "    \n",
    "    if (os.path.isfile(comments_folder+'/comments.json') ):\n",
    "        with open(comments_folder+'/comments.json') as f:\n",
    "            comments_data = json.load(f)\n",
    "        #pprint(comments_data)\n",
    "        comments_df = json_normalize(comments_data['comments'])\n",
    "\n",
    "        post_id = len(post)\n",
    "        stop_word = ['post.','photo.','comment.','video.','album.', 'link.','event.','question.']\n",
    "\n",
    "        user_id_from = unknown_friend_id\n",
    "        user_id_to = unknown_friend_id\n",
    "        post_activity = 999 # some default value\n",
    "        timestamp = time.time()\n",
    "        timestamp_date = datetime.datetime.fromtimestamp(timestamp).isoformat()\n",
    "\n",
    "        for i in range(0, len(comments_df)):\n",
    "            timestamp = comments_df.loc[i]['timestamp']\n",
    "            timestamp_date = datetime.datetime.fromtimestamp(timestamp).isoformat()\n",
    "\n",
    "            title = comments_df.loc[i]['title']\n",
    "            words = title.split(' ')\n",
    "            #user_id_from = my_id\n",
    "\n",
    "            if ('replied to' in title):\n",
    "                user_id_from = my_id\n",
    "                if ('own ' in title):\n",
    "                    user_id_to = my_id\n",
    "                else:\n",
    "                    counter = 0\n",
    "                    while (words[counter] != 'to'):\n",
    "                        counter += 1\n",
    "\n",
    "                    counter += 1\n",
    "                    user_to_name =''\n",
    "                    while (words[counter] not in stop_word):\n",
    "                        user_to_name = user_to_name+words[counter]+' '\n",
    "                        counter += 1\n",
    "                    user_to_name = user_to_name[:-3] \n",
    "                    user_to_name = unidecode_user_names(user_to_name) #get names compatible with friends' list\n",
    "                    try:\n",
    "                        user_id_to = friends_df.loc[friends_df['name']== user_to_name,'unique_id'].values[0]\n",
    "                    except :\n",
    "                        try:\n",
    "                            #print(user_to_name)\n",
    "                            user_id_to = groups_df.loc[groups_df['group_name']== user_to_name,'group_id'].values[0]\n",
    "                            #print(user_id_to)\n",
    "                        except : \n",
    "                            user_id_to = unknown_friend_id\n",
    "\n",
    "                post_activity = 2\n",
    "            elif ('commented on' in title):\n",
    "\n",
    "                counter = 0\n",
    "                #set user_id_from\n",
    "                user_id_from = my_id\n",
    "                if ('own' in title):\n",
    "\n",
    "                    user_id_to = my_id\n",
    "                else:\n",
    "                    user_name =''\n",
    "                    while (words[counter] != 'commented'):\n",
    "                        user_name = user_name+words[counter]+' '\n",
    "                        counter += 1\n",
    "                    user_name = user_name[:-1]\n",
    "                    user_name = unidecode_user_names(user_name)\n",
    "                    try: \n",
    "                        user_id_from = my_id if (user_name == my_name) else friends_df.loc[friends_df['name']== user_name,'unique_id'].values[0]\n",
    "\n",
    "                    except:\n",
    "                        user_id_from = unknown_friend_id\n",
    "\n",
    "                    #set the variable user_id_to\n",
    "                    \n",
    "                    while (words[counter] != 'on'): # skip 'on'\n",
    "                        counter += 1 \n",
    "                    #print(words[counter+1])\n",
    "                    \n",
    "                    user_to_name = ''\n",
    "                    try:\n",
    "                        while (words[counter] not in stop_word):\n",
    "\n",
    "                            user_to_name = user_to_name+words[counter]+' '\n",
    "                            counter += 1\n",
    "                        #print(user_to_name)\n",
    "                        user_to_name = unidecode_user_names(user_to_name[:-3]) # unidecode unusal characters\n",
    "                        try:\n",
    "                            user_id_to= friends_df.loc[friends_df['name']== user_to_name,'unique_id'].values[0]\n",
    "                        except:\n",
    "                            try:\n",
    "\n",
    "                                user_id_to = groups_df.loc[groups_df['group_name']== user_to_name,'group_id'].values[0]\n",
    "                                #print(user_id_to)\n",
    "                            except : \n",
    "                                user_id_to = unknown_friend_id \n",
    "                    except : \n",
    "                        user_id_to = unknown_friend_id\n",
    "                post_activity = 2\n",
    "\n",
    "            post = post.append(pd.DataFrame({'user_id_from':user_id_from, 'user_id_to':user_id_to,\n",
    "                                             'post_id':post_id, 'timestamp':timestamp, 'timestamp_date':timestamp_date,\n",
    "                                             'post_activity':post_activity},\n",
    "                                            index=[0]), ignore_index=True, sort=False)\n",
    "            post_id += 1\n",
    "    \n",
    "    return post\n",
    "'''\n",
    "#test this unit\n",
    "#directoryPath = '/media/santhilata/SANTHI/facebook-paulyoung583234/'\n",
    "directoryPath = '/media/santhilata/SANTHI/facebook-maitevanalboom-3/'\n",
    "#outputPath = '/home/santhilata/Desktop/testFolder/paul'\n",
    "outputPath = '/home/santhilata/Desktop/testFolder/maite'\n",
    "post = pd.DataFrame(columns = ['user_id_from','user_id_to','post_id','timestamp','timestamp_date','post_activity'])\n",
    "read_comments(directoryPath, outputPath, post)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#test this unit\\n#directoryPath = '/media/santhilata/SANTHI/facebook-paulyoung583234/'\\ndirectoryPath = '/media/santhilata/SANTHI/facebook-maitevanalboom-3/'\\n#outputPath = '/home/santhilata/Desktop/testFolder/paul'\\noutputPath = '/home/santhilata/Desktop/testFolder/maite'\\nread_likes_reactions(directoryPath,outputPath,post)\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_likes_reactions(directoryPath,outputPath,post):\n",
    "    # this function adds likes data to 'post' data frame\n",
    "    friends_df = pd.read_csv(outputPath+'/master_file_for_info_all_friends.csv')\n",
    "    groups_df = pd.read_csv(outputPath+'/groups.csv')\n",
    "    likes_reactions_folder = directoryPath+'/likes_and_reactions'\n",
    "    legit_reactions = ['WOW', 'HAHA', 'LIKE', 'LOVE', 'SORRY']\n",
    "    i = len(post)\n",
    "    \n",
    "    counter = 0 # for this file    \n",
    "    with open(likes_reactions_folder+'/posts_and_comments.json') as f:\n",
    "        likes_data = json.load(f)\n",
    "        \n",
    "    likes_df = json_normalize(likes_data['reactions'])\n",
    "    reactions = ['likes','liked','reacted'] # interested only in these lines\n",
    "    like_reacted_lines = [ line for line in likes_df['title'] if any(word in line for word in reactions)] # no need of this\n",
    "    \n",
    "    for line in like_reacted_lines:\n",
    "        \n",
    "        user_id_from = my_id\n",
    "        user_id_to = 'u_0'\n",
    "        timestamp = likes_df.loc[counter]['timestamp']\n",
    "        timestamp_date = datetime.datetime.fromtimestamp(timestamp).isoformat()\n",
    "        \n",
    "        post_id = i\n",
    "        post_activity = 1 # for likes\n",
    "        some_body = ''\n",
    "        words = line.split(' ') #  a list of words\n",
    "        try:\n",
    "            if any(term in line for term in ['likes','liked']):\n",
    "                j = 3    \n",
    "            elif any(term in line for term in ['reacted']): \n",
    "                j = 4\n",
    "\n",
    "            while ('\\'s' not in words[j] ):\n",
    "                some_body = some_body +words[j]+' '\n",
    "                j += 1\n",
    "            some_body = unidecode_user_names(some_body+words[j][:-2])\n",
    "            \n",
    "            try:\n",
    "                user_id_to = friends_df.loc[friends_df['name']== some_body,'unique_id'].values[0]\n",
    "            except:\n",
    "                try:    \n",
    "                    user_id_to = groups_df.loc[groups_df['group_name']== some_body,'group_id'].values[0]\n",
    "                    #print(user_id_to)\n",
    "                except : \n",
    "                    user_id_to = unknown_friend_id #  non friend's id\n",
    "            \n",
    "        except:\n",
    "            continue\n",
    "                \n",
    "        # add info to data frame\n",
    "        post = post.append(pd.DataFrame({'user_id_from':user_id_from, 'user_id_to':user_id_to, \n",
    "                                        'post_id':post_id, 'timestamp':timestamp,'timestamp_date':timestamp_date,\n",
    "                                        'post_activity':post_activity},\n",
    "                                       index=[0]), ignore_index=True, sort=False)\n",
    "        i += 1\n",
    "        counter += 1\n",
    "\n",
    "    return post\n",
    "\n",
    "'''\n",
    "#test this unit\n",
    "#directoryPath = '/media/santhilata/SANTHI/facebook-paulyoung583234/'\n",
    "directoryPath = '/media/santhilata/SANTHI/facebook-maitevanalboom-3/'\n",
    "#outputPath = '/home/santhilata/Desktop/testFolder/paul'\n",
    "outputPath = '/home/santhilata/Desktop/testFolder/maite'\n",
    "read_likes_reactions(directoryPath,outputPath,post)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#test this unit\\n#directoryPath = '/media/santhilata/SANTHI/facebook-paulyoung583234/'\\ndirectoryPath = '/media/santhilata/SANTHI/facebook-maitevanalboom-3/'\\n#outputPath = '/home/santhilata/Desktop/testFolder/paul'\\noutputPath = '/home/santhilata/Desktop/testFolder/maite'\\nread_posts(directoryPath,outputPath,post)\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_posts(directoryPath,outputPath,post):\n",
    "    # This function reads your_posts.json for the post.csv file\n",
    "    friends_df = pd.read_csv(outputPath+'/master_file_for_info_all_friends.csv')\n",
    "    posts_folder = directoryPath+'/posts'\n",
    "    groups_df = pd.read_csv(outputPath+'/groups.csv')\n",
    "    '''\n",
    "    posts_file = ''\n",
    "    for _,_, files in os.walk(posts_folder):\n",
    "        #print(files)\n",
    "        for file in files:\n",
    "            if( re.match(r'your_posts*[.json]',file)):\n",
    "                #print(file)\n",
    "                posts_file = file\n",
    "                break\n",
    "    '''\n",
    "    #yourPosts = posts_folder +'/'+posts_file\n",
    "    yourPosts = posts_folder + get_file(posts_folder,'posts')\n",
    "    \n",
    "    \n",
    "    with open(yourPosts) as f:\n",
    "        my_posts_data = json.load(f)\n",
    "    #**********************\n",
    "    # pprint(my_posts_data)\n",
    "    #**********************\n",
    "    if (yourPosts == (posts_folder +'/your_posts.json')):\n",
    "        my_posts_df = json_normalize(my_posts_data['status_updates'])\n",
    "    elif (yourPosts == (posts_folder +'/your_posts_1.json')):\n",
    "        my_posts_df =json_normalize(my_posts_data)\n",
    "    #print(my_posts_df.head(1))\n",
    "    \n",
    "    post_id = len(post)\n",
    "    for i in range(0,len(my_posts_df)):\n",
    "        timestamp = my_posts_df.loc[i].timestamp\n",
    "        timestamp_date = datetime.datetime.fromtimestamp(timestamp).isoformat()\n",
    "        user_id_from = my_id\n",
    "        user_id_to = unknown_friend_id\n",
    "        post_activity = 0\n",
    "         \n",
    "        title = str(my_posts_df.loc[i]['title'])  \n",
    "        attachments = my_posts_df.loc[i]['attachments']\n",
    "                \n",
    "        legit_words = ['shared', 'wrote on','posted', 'added','updated','uploaded','likes']\n",
    "        length_my_name = len(my_name)\n",
    "               \n",
    "        '''\n",
    "        #The title is nan when there is an attachment not NaN\n",
    "        if (title != 'nan' and attachments == 'NaN') :\n",
    "            print(my_posts_df.loc[i]['attachments'])\n",
    "        '''\n",
    "        \n",
    "        if (title != 'nan'):\n",
    "            #print(my_posts_df.loc[i])\n",
    "            #print(attachments)\n",
    "            \n",
    "            if (' shared' in title):\n",
    "                title = title[(length_my_name+1):len(title)] # remove user_id_from\n",
    "                \n",
    "                words = title.split(' ')\n",
    "                if (len(words) <= 3):\n",
    "                    user_id_to = my_id\n",
    "                    post_activity = 3\n",
    "                elif (words[len(words)-1] =='timeline.'):\n",
    "                    \n",
    "                    to_index = sum(i+1 for i,word in enumerate(words) if words[i]=='to')\n",
    "                    some_body = ''\n",
    "                    \n",
    "                    while(words[to_index] != 'timeline.'):\n",
    "                        some_body = some_body+words[to_index]+' '\n",
    "                        to_index += 1\n",
    "                    some_body = unidecode_user_names(some_body[:-3])\n",
    "                    try:\n",
    "                        user_id_to = friends_df.loc[friends_df['name']== some_body,'unique_id'].values[0]\n",
    "                    except:\n",
    "                        try:    \n",
    "                            user_id_to = groups_df.loc[groups_df['group_name']== some_body,'group_id'].values[0]\n",
    "                            #print(user_id_to)\n",
    "                        except : \n",
    "                            user_id_to = unknown_friend_id #  non friend's id\n",
    "\n",
    "                    post_activity = 4\n",
    "            \n",
    "            title = str(my_posts_df.loc[i]['title'])  \n",
    "            words = title.split(' ')\n",
    "            if(' wrote' in title and (words[len(words)-1] =='Timeline.')):\n",
    "                title = title[(length_my_name+1):len(title)] # remove user_id_from\n",
    "                \n",
    "                words = title.split(' ')\n",
    "                on_index = sum(i+1 for i,word in enumerate(words) if words[i]=='on')\n",
    "                some_body = ''\n",
    "\n",
    "                while(words[on_index] != 'Timeline.'):\n",
    "                    some_body = some_body+words[on_index]+' '\n",
    "                    on_index += 1\n",
    "                some_body = unidecode_user_names(some_body[:-3])\n",
    "                try:\n",
    "                    user_id_to = friends_df.loc[friends_df['name']== some_body,'unique_id'].values[0]\n",
    "                    #print(some_body +' ** '+user_id_to)\n",
    "                except:\n",
    "                    try:    \n",
    "                        user_id_to = groups_df.loc[groups_df['group_name']== some_body,'group_id'].values[0]\n",
    "                        #print(user_id_to)\n",
    "                    except : \n",
    "                        user_id_to = unknown_friend_id #  non friend's id\n",
    "\n",
    "                post_activity = 4\n",
    "\n",
    "            title = str(my_posts_df.loc[i]['title'])  \n",
    "            words = title.split(' ')    \n",
    "            if(' posted' in title):\n",
    "                ### always 'posted in' a group\n",
    "                title = title[(length_my_name+1):len(title)] # remove user_id_from\n",
    "                words = title.split(' ')\n",
    "                \n",
    "                in_index = sum(i+1 for i,word in enumerate(words) if words[i]=='in')\n",
    "                \n",
    "                some_body = ''\n",
    "                \n",
    "                for word in range(in_index,len(words)):\n",
    "                    some_body = some_body+words[word]+' '\n",
    "                some_body = unidecode_user_names(some_body[:-2])\n",
    "                #print(some_body)\n",
    "                try:\n",
    "                    user_id_to = friends_df.loc[friends_df['name']== some_body,'unique_id'].values[0]\n",
    "                    #print(some_body +' ** '+user_id_to)\n",
    "                except:\n",
    "                    try:    \n",
    "                        user_id_to = groups_df.loc[groups_df['group_name']== some_body,'group_id'].values[0]\n",
    "                        #print(some_body +' ** '+user_id_to)\n",
    "                    except : \n",
    "                        user_id_to = unknown_friend_id #  non friend's id\n",
    "                        #print(some_body +' ** '+user_id_to)\n",
    "                post_activity = 4\n",
    "                \n",
    "            title = str(my_posts_df.loc[i]['title'])  \n",
    "            words = title.split(' ')    \n",
    "            if (' added' in title):\n",
    "                title = title[(length_my_name+1):len(title)] # remove user_id_from\n",
    "                words = title.split(' ')\n",
    "                \n",
    "                \n",
    "                if ('to' in title and words[len(words)-1] =='timeline.'):\n",
    "                    to_index = sum(i+1 for i,word in enumerate(words) if words[i]=='to')\n",
    "                    some_body = ''\n",
    "                    \n",
    "                    while(words[to_index] != 'timeline.'):\n",
    "                        some_body = some_body+words[to_index]+' '\n",
    "                        to_index += 1\n",
    "                    some_body = unidecode_user_names(some_body[:-3])\n",
    "                    #print(title +' ** '+some_body)\n",
    "                    try:\n",
    "                        user_id_to = friends_df.loc[friends_df['name']== some_body,'unique_id'].values[0]\n",
    "                    except:\n",
    "                        try:    \n",
    "                            user_id_to = groups_df.loc[groups_df['group_name']== some_body,'group_id'].values[0]\n",
    "                            #print(user_id_to)\n",
    "                        except : \n",
    "                            user_id_to = unknown_friend_id #  non friend's id\n",
    "\n",
    "                    post_activity = 4\n",
    "            \n",
    "                else:\n",
    "                    user_id_to = my_id\n",
    "                    post_activity =0\n",
    "                \n",
    "            title = str(my_posts_df.loc[i]['title'])  \n",
    "            words = title.split(' ')    \n",
    "            if(' updated' in title):  \n",
    "                title = title[(length_my_name+1):len(title)] # remove user_id_from\n",
    "                words = title.split(' ')\n",
    "                #print(title)\n",
    "                \n",
    "                if ('group' in title):\n",
    "                    some_body = ''\n",
    "                    in_index = sum(i+1 for i,word in enumerate(words) if words[i]=='in')\n",
    "                \n",
    "                    for word in range(in_index,len(words)):\n",
    "                        some_body = some_body+words[word]+' '\n",
    "                    some_body = unidecode_user_names(some_body[:-2])\n",
    "                    #print(some_body) \n",
    "                    user_id_to = groups_df.loc[groups_df['group_name']== some_body,'group_id'].values[0]\n",
    "                    post_activity = 4\n",
    "                    #print(user_id_to)\n",
    "                else : \n",
    "                    user_id_to = my_id #  self id\n",
    "                    post_activity = 0\n",
    "                    #print(user_id_to)\n",
    "                    \n",
    "            title = str(my_posts_df.loc[i]['title'])  \n",
    "            words = title.split(' ')    \n",
    "            if (' likes' in title or ' liked' in title):  \n",
    "                title = title[(length_my_name+1):len(title)] # remove user_id_from\n",
    "                words = title.split(' ')\n",
    "                #print(title)\n",
    "                \n",
    "                user_id_to = my_id #  self id\n",
    "                post_activity = 1\n",
    "                \n",
    "            # add info to data frame\n",
    "            post = post.append(pd.DataFrame({'user_id_from':user_id_from, 'user_id_to':user_id_to, \n",
    "                                            'post_id':post_id, 'timestamp':timestamp,'timestamp_date':timestamp_date,\n",
    "                                            'post_activity':post_activity},\n",
    "                                           index=[0]), ignore_index=True, sort=False)\n",
    "\n",
    "            post_id += 1\n",
    "                \n",
    "    return post\n",
    "'''\n",
    "#test this unit\n",
    "#directoryPath = '/media/santhilata/SANTHI/facebook-paulyoung583234/'\n",
    "directoryPath = '/media/santhilata/SANTHI/facebook-maitevanalboom-3/'\n",
    "#outputPath = '/home/santhilata/Desktop/testFolder/paul'\n",
    "outputPath = '/home/santhilata/Desktop/testFolder/maite'\n",
    "read_posts(directoryPath,outputPath,post)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_post(directoryPath,outputPath):\n",
    "    # THis function is to create post data frame and hence post.csv\n",
    "    # The post is the combination of two functions\n",
    "       \n",
    "    # create empty data frame post\n",
    "    post = pd.DataFrame(columns = ['user_id_from','user_id_to','post_id','timestamp','timestamp_date','post_activity'])\n",
    "    post = read_comments(directoryPath,outputPath,post)\n",
    "    post = read_likes_reactions(directoryPath,outputPath,post)\n",
    "    post = read_posts(directoryPath,outputPath,post)    \n",
    "    post.to_csv(outputPath+'/post.csv', sep=',') # create post.csv\n",
    "    \n",
    "    #print(post.head(10))\n",
    "    #print(post.tail(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Main function ** ( It will be called from the GUI. This should help if someone is making a single class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_fn():\n",
    "    \n",
    "    # get input directory path and set output directory path\n",
    "    directoryPath= directory_path.get() \n",
    "    outputPath = output_path.get()\n",
    "    \n",
    "    # testing\n",
    "    print(\"--directory path-- testing\"+directoryPath) \n",
    "    \n",
    "    # create friend.csv\n",
    "    my_name = set_my_name(directoryPath)\n",
    "    generate_friend_csv(directoryPath,outputPath) \n",
    "    \n",
    "    #create group.csv\n",
    "    if (os.path.exists(directoryPath+'/groups')):\n",
    "        create_group_information(directoryPath, outputPath)\n",
    "        group_posts_comments(directoryPath, outputPath)\n",
    "    else:\n",
    "        temp_df = pd.DataFrame(columns=('user_id','group_id','admin/member','group_name','joined_date'))\n",
    "        temp_df.to_csv(outputPath+'/groups.csv', sep=',')\n",
    "        temp_comments_df = pd.DataFrame(columns=('user_id','comment_post', 'length', 'timestamp', 'timestamp_date',\n",
    "                                                 'group_id','group_name'))\n",
    "        temp_comments_df.to_csv(outputPath+'/groups_comments.csv',sep=',')\n",
    "        \n",
    "    #create message.csv\n",
    "    if (os.path.exists(directoryPath+'/messages')):\n",
    "        read_messages_inbox(directoryPath,outputPath)\n",
    "    else:\n",
    "        temp_message_df = pd.DataFrame(columns=('from_id', 'to_id', 'length_of_msg', 'timestamp_ms','timestamp_date'))\n",
    "        temp_message_df.to_csv(outputPath+'/message.csv',sep=',')\n",
    "    \n",
    "    # create post.csv\n",
    "    if (os.path.exists(directoryPath+'/posts')):\n",
    "        create_post(directoryPath,outputPath)\n",
    "    else:\n",
    "        temp_post_df = pd.DataFrame(columns=('user_id_from','user_id_to','post_id','timestamp',\n",
    "                                             'timestamp_date','post_activity'))\n",
    "        temp_post_df.to_csv(outputPath+'/post.csv',sep=',')\n",
    "    \n",
    "    # testing\n",
    "    print(\"Output directory created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GUI. \n",
    "**For it's' simplicity, I chose tkinter. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter \n",
    "from tkinter import *\n",
    "from tkinter import filedialog\n",
    "\n",
    "#from PIL import Image, ImageTk\n",
    "\n",
    "global directory_path\n",
    "global output_path\n",
    "global spinner_wheel\n",
    "\n",
    "def get_directory_path(initialdir='.'): #open the file \n",
    "    folder_name = tkinter.filedialog.askdirectory()  \n",
    "    directory_path.set(folder_name)\n",
    "    output_path.set(folder_name + '/outputDir' ) # sets the ouput directory\n",
    "        \n",
    "def generate_output():\n",
    "    print(\"inside main_function\")\n",
    "    spinner_wheel.set(\"processing... ...\")\n",
    "    main_fn()\n",
    "    spinner_wheel.set(\"Process complete. Check your outputDir\")\n",
    "\n",
    "win = Tk()\n",
    "win.title(\"Anonymization\")\n",
    "win.configure(background= '#00aa90')\n",
    "win.geometry(\"500x200\") #You want the size of the app to be 500x200\n",
    "win.resizable(0, 0) \n",
    "\n",
    "back = tkinter.Frame(master=win,bg='black')\n",
    "#back.pack_propagate(0) #Don't allow the widgets inside to determine the frame's width / height\n",
    "#back.pack(fill=tkinter.BOTH, expand=1) \n",
    "#win.option_add(\"*Button.Background\", \"black\")\n",
    "#win.option_add(\"*Button.Foreground\", \"white\")\n",
    "win.option_add(\"*Label.Foreground\", \"#BB0000\")\n",
    "\n",
    "directory_path = StringVar()\n",
    "output_path = StringVar()\n",
    "spinner_wheel = StringVar()\n",
    "spinner_wheel.set(\"          \")\n",
    "\n",
    "l1 = Label(win, text=\"Anonymization Software\", font=('Helvetica', 18, 'bold'))\n",
    "l1.config()\n",
    "\n",
    "l1.pack() \n",
    "'''\n",
    "load = Image.open(\"sunflower.jpg\")\n",
    "render = ImageTk.PhotoImage(load)\n",
    "img = Label( image=render)\n",
    "img.image = render\n",
    "img.place(x=10, y=10)\n",
    "'''\n",
    "\n",
    "b1 = tkinter.Button(win, text='Set directory path', font=('Helvetica', 12, 'bold'),command=get_directory_path)\n",
    "b1.pack(side=LEFT, padx=5, pady=15)  \n",
    "\n",
    "b2 = Button(win, text='Generate output', font=('Helvetica', 12, 'bold'), command=generate_output)\n",
    "b2.pack(side=LEFT, padx=50, pady=15)\n",
    "\n",
    "b3 =Button(win, text=\"Quit\", font=('Helvetica', 12, 'bold'), command=win.destroy)\n",
    "b3.pack(side=LEFT, padx=5, pady=15)\n",
    "\n",
    "#l2 = Label(win, textvariable =spinner_wheel)\n",
    "#l2.pack() \n",
    "\n",
    "#Button(win, text=\"Quit\", command=win.destroy).pack(side=LEFT, padx=5, pady=10)\n",
    "# TO DO : make a label saying that you can close the window after creation of the output\n",
    "win.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
